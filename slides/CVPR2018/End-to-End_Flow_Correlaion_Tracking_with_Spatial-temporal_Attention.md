+++
#### End-to-End Flow Correlation Tracking with Spatial-temporal Attention
###### Zheng Zhu, Wei Wu, Wei Zou, Junjie Yan
<div class="container">
  <div class="col">
    <u><b>Abstract</b></u><br>
    Most of existing Discriminative Correlation Filters (DCF) trackers only consider appearace features of current frame, and hardly benefit from motion and inter-frame information. In this work, we focus on making use of the rich flow information in consecutive frames to improve the feature representation and the tracking accuracy. Firstly, individual components, including optical flow estimation, feature extraction, aggregation and correaltion filter tracking are formulated as special layers in network. To the best of our knowledge, this is the first work to jointly train flow and tracking task in a deep learning framework. For adaptive aggregation, we propose a novel spatial-temporal attention mechanism.<br>
    <u><b>Contribution</b></u><br>
    <ul>
      <li>We develop an end-to-end flow correlation tracking framework to improve the feature representation and the tracking accuracy. To the best of our knowledge, this is the first work to jointly train flow and tracking task in a deep learning framework.</li>
      <li>A novel spatial-temporal attention mechanism is proposed, which can adatively aggregate the warped and current feature maps.</li>
    </ul><br>
    <u><b>Links</b></u><br>
    <ul>
      <li><a href="https://arxiv.org/abs/1711.01124">論文</a></li>
    </ul><br>
  </div>
  <div class="col">
    <img width="100%" src="https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/0ff3b840b49bdfa32ffd89f9965dd18766313c32/4-Figure2-1.png">
    <img width="100%" src="https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/0ff3b840b49bdfa32ffd89f9965dd18766313c32/5-Figure3-1.png">
  </div>
</div>