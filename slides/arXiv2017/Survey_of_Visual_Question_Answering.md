#### Survey of Visual Question Answering: Datasets and Techniques
###### Akshay Kumar Gupta
<div class="container">
  <div class="col">
    <u><b>Abstract</b></u><br>
    Visual question answering (or VQA) is a new and exciting problem that combines natural language processing and computer vision techniques.
    Computer vision techniques must be used to understand the image and NLP techniques must be used to understand the question.
    Moreover, both must be combined to effectively answer the question in context of the image.
    The task typically involves showing an image to a computer and asking a question about that image which the computer must answer.
    The answer could be in any of the following forms: a word, a phrase, a yes/no answer, choosing out of several possible answers, or a fill in the blank answer. 
    We survey the most prominent of models ad listed their performance over large-scale datasets. <br>
    <u><b>Contribution</b></u><br>
    <ul>
      <li></li>
    </ul><br>
    <u><b>Links</b></u><br>
    <ul>
      <li><a href="https://arxiv.org/abs/1705.03865">paper</a></li>
    </ul><br>
  </div>
  <div class="col">
    <img width="100%" src="https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/637648198f9e91654ce27eaaa40512f2dc870fc1/3-Figure3-1.png">
    <img width="100%" src="https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/637648198f9e91654ce27eaaa40512f2dc870fc1/2-Figure1-1.png">
  </div>
</div>